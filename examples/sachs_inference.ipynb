{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42100c02-d1da-42d5-abb3-07a6547ea2c4",
   "metadata": {},
   "source": [
    "### Sachs data\n",
    "\n",
    "[Sachs Protein Data](https://perso.univ-rennes1.fr/valerie.monbet/GM/Sachs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b3101e-bc4c-4a2d-a913-2407a6f8088c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX backend: cpu\n"
     ]
    }
   ],
   "source": [
    "#%pip install ../. \n",
    "#%pip install cdt\n",
    "from cdt.data import load_dataset\n",
    "import networkx as nx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from vamsl.metrics import neg_ave_log_likelihood\n",
    "from vamsl.utils import visualize_ground_truth\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "key=random.PRNGKey(343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2ebcc-94cf-486d-a41b-6969a0c965e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the graph and data\n",
    "sachs_data, sachs_graph = load_dataset(\"sachs\")\n",
    "\n",
    "adjacency = jnp.array(nx.to_numpy_array(sachs_graph))\n",
    "visualize_ground_truth(adjacency)\n",
    "\n",
    "#num_rows = 853+902+911+723+810+799+848+913+707#+899+753+868+759+927\n",
    "data = jnp.log(jnp.array(sachs_data)[0:853,:])\n",
    "data = jnp.vstack([data, jnp.log(jnp.array(sachs_data)[853+902+911+723:853+902+911+723+810,:])])\n",
    "indicator = jnp.array([0 if i<853 else 1 for i in range(1755)])\n",
    "\n",
    "# Use only subset of data\n",
    "N = 250\n",
    "key, subk = random.split(key)\n",
    "sample = jax.random.choice(subk, jnp.arange(data.shape[0]), shape=(N,), replace=False, axis=0)\n",
    "data, indicator = data[sample], indicator[sample]\n",
    "\n",
    "print('Data shape: \\n', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90345a4c-e432-481e-9b18-4915b925e7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'kornblau'\n",
    "#dataset = 'iyer'\n",
    "\n",
    "if dataset == 'kornblau':\n",
    "    proteins = ['AKT', 'AKT.p308', 'AKT.p473', 'BAD', 'BAD.p112', 'BAD.p136', 'BAD.p155', 'BAX', 'BCL2', 'BCLXL', 'CCND1', 'GSK3', 'GSK3.p', 'MYC', 'PTEN', 'PTEN.p', 'TP53', 'XIAP']\n",
    "    FAB_groups = ['M2', 'M4']#['M0', 'M1', 'M2', 'M4']\n",
    "\n",
    "    kornblau_df = pd.read_excel('./Datasets/Kornblau et al. 2009.xls')\n",
    "    kornblau_FAB_df = kornblau_df[proteins][kornblau_df['FAB'].isin(FAB_groups)]\n",
    "    data = kornblau_FAB_df.values\n",
    "    indicator = kornblau_df['FAB'][kornblau_df['FAB'].isin(FAB_groups)].astype('category').cat.codes.values\n",
    "    #[kornblau_FAB_df.hist(prot) for prot in proteins] # plot protein histograms\n",
    "    \n",
    "elif dataset == 'iyer':\n",
    "    iyer_df = pd.read_html((file:='./Datasets/Iyer et al. 1999 - stripped.htm'), header=0)[0][[*pd.read_html(file, header=0)[0].columns[5:16]]]\n",
    "    data = iyer_df.values\n",
    "    #[iyer_df.hist(col) for col in iyer_df.cols] # plot protein histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b2b5df-6015-4181-a0dc-08e6adb08fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed data shape: \n",
      " (92, 18)\n",
      "Left-out data shape: \n",
      " (35, 18)\n"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "key, subk = random.split(key)\n",
    "observed = random.bernoulli(subk, p=jnp.float32(0.8), shape=(data.shape[0],))\n",
    "\n",
    "X, X_lo = data[observed], data[~observed]\n",
    "sc =  StandardScaler()\n",
    "X, X_lo = sc.fit_transform(X), sc.transform(X_lo)\n",
    "\n",
    "X_indicator, X_lo_indicator = indicator[observed], indicator[~observed]\n",
    "\n",
    "print('Observed data shape: \\n', X.shape)\n",
    "print('Left-out data shape: \\n', X_lo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9526d8db-2e3d-4027-98a0-36d2ac5d5842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>9.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.253029e-15</td>\n",
       "      <td>-5.309762e-16</td>\n",
       "      <td>3.704766e-16</td>\n",
       "      <td>-1.384158e-15</td>\n",
       "      <td>-3.970254e-16</td>\n",
       "      <td>-8.121523e-16</td>\n",
       "      <td>2.033398e-15</td>\n",
       "      <td>5.654897e-15</td>\n",
       "      <td>2.292852e-15</td>\n",
       "      <td>6.709609e-16</td>\n",
       "      <td>-2.560754e-15</td>\n",
       "      <td>2.148040e-15</td>\n",
       "      <td>1.117464e-15</td>\n",
       "      <td>-4.054728e-16</td>\n",
       "      <td>1.236330e-15</td>\n",
       "      <td>3.598571e-15</td>\n",
       "      <td>-2.285611e-15</td>\n",
       "      <td>1.975322e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "      <td>1.005479e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.676363e+00</td>\n",
       "      <td>-1.664124e+00</td>\n",
       "      <td>-1.766485e+00</td>\n",
       "      <td>-2.585614e+00</td>\n",
       "      <td>-2.534489e+00</td>\n",
       "      <td>-2.639611e+00</td>\n",
       "      <td>-2.845548e+00</td>\n",
       "      <td>-2.472790e+00</td>\n",
       "      <td>-3.565280e+00</td>\n",
       "      <td>-2.076187e+00</td>\n",
       "      <td>-1.787166e+00</td>\n",
       "      <td>-3.001011e+00</td>\n",
       "      <td>-2.691461e+00</td>\n",
       "      <td>-2.385176e+00</td>\n",
       "      <td>-3.265247e+00</td>\n",
       "      <td>-2.716546e+00</td>\n",
       "      <td>-1.513740e+00</td>\n",
       "      <td>-2.189053e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.288247e-01</td>\n",
       "      <td>-7.716828e-01</td>\n",
       "      <td>-7.089831e-01</td>\n",
       "      <td>-6.018815e-01</td>\n",
       "      <td>-7.085467e-01</td>\n",
       "      <td>-7.811015e-01</td>\n",
       "      <td>-6.976184e-01</td>\n",
       "      <td>-5.418395e-01</td>\n",
       "      <td>-6.194674e-01</td>\n",
       "      <td>-6.935238e-01</td>\n",
       "      <td>-5.955841e-01</td>\n",
       "      <td>-7.222243e-01</td>\n",
       "      <td>-6.414697e-01</td>\n",
       "      <td>-6.948456e-01</td>\n",
       "      <td>-5.884988e-01</td>\n",
       "      <td>-5.067975e-01</td>\n",
       "      <td>-6.665625e-01</td>\n",
       "      <td>-7.166581e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.969977e-02</td>\n",
       "      <td>-1.645814e-01</td>\n",
       "      <td>-1.308073e-01</td>\n",
       "      <td>-4.445648e-02</td>\n",
       "      <td>-7.907613e-02</td>\n",
       "      <td>-2.189658e-04</td>\n",
       "      <td>-7.924774e-02</td>\n",
       "      <td>3.898176e-02</td>\n",
       "      <td>4.275741e-02</td>\n",
       "      <td>-5.171408e-02</td>\n",
       "      <td>-1.619314e-01</td>\n",
       "      <td>-4.893219e-02</td>\n",
       "      <td>-1.701493e-01</td>\n",
       "      <td>-7.846760e-02</td>\n",
       "      <td>1.477090e-01</td>\n",
       "      <td>3.428554e-02</td>\n",
       "      <td>-1.858846e-01</td>\n",
       "      <td>-8.756966e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.496640e-01</td>\n",
       "      <td>7.656004e-01</td>\n",
       "      <td>6.120723e-01</td>\n",
       "      <td>5.625272e-01</td>\n",
       "      <td>6.001609e-01</td>\n",
       "      <td>7.229543e-01</td>\n",
       "      <td>5.954765e-01</td>\n",
       "      <td>6.995140e-01</td>\n",
       "      <td>5.690816e-01</td>\n",
       "      <td>4.298317e-01</td>\n",
       "      <td>5.651564e-01</td>\n",
       "      <td>7.223995e-01</td>\n",
       "      <td>5.922114e-01</td>\n",
       "      <td>5.340595e-01</td>\n",
       "      <td>7.768874e-01</td>\n",
       "      <td>7.372384e-01</td>\n",
       "      <td>2.962520e-01</td>\n",
       "      <td>6.477266e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.786954e+00</td>\n",
       "      <td>2.808915e+00</td>\n",
       "      <td>3.554083e+00</td>\n",
       "      <td>2.913900e+00</td>\n",
       "      <td>3.014735e+00</td>\n",
       "      <td>2.130744e+00</td>\n",
       "      <td>2.403153e+00</td>\n",
       "      <td>3.090859e+00</td>\n",
       "      <td>2.045529e+00</td>\n",
       "      <td>3.880044e+00</td>\n",
       "      <td>4.051580e+00</td>\n",
       "      <td>4.314225e+00</td>\n",
       "      <td>2.418361e+00</td>\n",
       "      <td>2.622432e+00</td>\n",
       "      <td>1.967016e+00</td>\n",
       "      <td>1.852461e+00</td>\n",
       "      <td>4.476083e+00</td>\n",
       "      <td>3.793297e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  9.200000e+01  9.200000e+01  9.200000e+01  9.200000e+01  9.200000e+01   \n",
       "mean   2.253029e-15 -5.309762e-16  3.704766e-16 -1.384158e-15 -3.970254e-16   \n",
       "std    1.005479e+00  1.005479e+00  1.005479e+00  1.005479e+00  1.005479e+00   \n",
       "min   -2.676363e+00 -1.664124e+00 -1.766485e+00 -2.585614e+00 -2.534489e+00   \n",
       "25%   -5.288247e-01 -7.716828e-01 -7.089831e-01 -6.018815e-01 -7.085467e-01   \n",
       "50%   -5.969977e-02 -1.645814e-01 -1.308073e-01 -4.445648e-02 -7.907613e-02   \n",
       "75%    4.496640e-01  7.656004e-01  6.120723e-01  5.625272e-01  6.001609e-01   \n",
       "max    2.786954e+00  2.808915e+00  3.554083e+00  2.913900e+00  3.014735e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  9.200000e+01  9.200000e+01  9.200000e+01  9.200000e+01  9.200000e+01   \n",
       "mean  -8.121523e-16  2.033398e-15  5.654897e-15  2.292852e-15  6.709609e-16   \n",
       "std    1.005479e+00  1.005479e+00  1.005479e+00  1.005479e+00  1.005479e+00   \n",
       "min   -2.639611e+00 -2.845548e+00 -2.472790e+00 -3.565280e+00 -2.076187e+00   \n",
       "25%   -7.811015e-01 -6.976184e-01 -5.418395e-01 -6.194674e-01 -6.935238e-01   \n",
       "50%   -2.189658e-04 -7.924774e-02  3.898176e-02  4.275741e-02 -5.171408e-02   \n",
       "75%    7.229543e-01  5.954765e-01  6.995140e-01  5.690816e-01  4.298317e-01   \n",
       "max    2.130744e+00  2.403153e+00  3.090859e+00  2.045529e+00  3.880044e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  9.200000e+01  9.200000e+01  9.200000e+01  9.200000e+01  9.200000e+01   \n",
       "mean  -2.560754e-15  2.148040e-15  1.117464e-15 -4.054728e-16  1.236330e-15   \n",
       "std    1.005479e+00  1.005479e+00  1.005479e+00  1.005479e+00  1.005479e+00   \n",
       "min   -1.787166e+00 -3.001011e+00 -2.691461e+00 -2.385176e+00 -3.265247e+00   \n",
       "25%   -5.955841e-01 -7.222243e-01 -6.414697e-01 -6.948456e-01 -5.884988e-01   \n",
       "50%   -1.619314e-01 -4.893219e-02 -1.701493e-01 -7.846760e-02  1.477090e-01   \n",
       "75%    5.651564e-01  7.223995e-01  5.922114e-01  5.340595e-01  7.768874e-01   \n",
       "max    4.051580e+00  4.314225e+00  2.418361e+00  2.622432e+00  1.967016e+00   \n",
       "\n",
       "                 15            16            17  \n",
       "count  9.200000e+01  9.200000e+01  9.200000e+01  \n",
       "mean   3.598571e-15 -2.285611e-15  1.975322e-15  \n",
       "std    1.005479e+00  1.005479e+00  1.005479e+00  \n",
       "min   -2.716546e+00 -1.513740e+00 -2.189053e+00  \n",
       "25%   -5.067975e-01 -6.665625e-01 -7.166581e-01  \n",
       "50%    3.428554e-02 -1.858846e-01 -8.756966e-02  \n",
       "75%    7.372384e-01  2.962520e-01  6.477266e-01  \n",
       "max    1.852461e+00  4.476083e+00  3.793297e+00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed data set\n",
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe39a43d-be34-494c-bef9-fe072284bbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.068168</td>\n",
       "      <td>-0.047086</td>\n",
       "      <td>-0.271721</td>\n",
       "      <td>-0.010764</td>\n",
       "      <td>-0.117387</td>\n",
       "      <td>0.143858</td>\n",
       "      <td>-0.405909</td>\n",
       "      <td>-0.074556</td>\n",
       "      <td>0.133895</td>\n",
       "      <td>0.089220</td>\n",
       "      <td>-0.071600</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>-0.619987</td>\n",
       "      <td>-0.169259</td>\n",
       "      <td>-0.153238</td>\n",
       "      <td>0.145333</td>\n",
       "      <td>0.050195</td>\n",
       "      <td>-0.455814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.852268</td>\n",
       "      <td>1.101955</td>\n",
       "      <td>1.052590</td>\n",
       "      <td>1.152810</td>\n",
       "      <td>0.912579</td>\n",
       "      <td>1.153690</td>\n",
       "      <td>1.001973</td>\n",
       "      <td>1.209683</td>\n",
       "      <td>1.113467</td>\n",
       "      <td>1.436906</td>\n",
       "      <td>0.632524</td>\n",
       "      <td>1.053231</td>\n",
       "      <td>0.943288</td>\n",
       "      <td>0.986321</td>\n",
       "      <td>1.215183</td>\n",
       "      <td>1.091717</td>\n",
       "      <td>1.029160</td>\n",
       "      <td>1.118408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.923010</td>\n",
       "      <td>-1.801510</td>\n",
       "      <td>-1.908166</td>\n",
       "      <td>-1.886591</td>\n",
       "      <td>-2.010072</td>\n",
       "      <td>-2.186242</td>\n",
       "      <td>-2.530499</td>\n",
       "      <td>-3.849462</td>\n",
       "      <td>-2.732487</td>\n",
       "      <td>-1.872328</td>\n",
       "      <td>-1.451265</td>\n",
       "      <td>-1.809318</td>\n",
       "      <td>-3.247888</td>\n",
       "      <td>-1.670656</td>\n",
       "      <td>-3.281368</td>\n",
       "      <td>-2.039341</td>\n",
       "      <td>-1.511725</td>\n",
       "      <td>-2.338709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.631240</td>\n",
       "      <td>-1.048411</td>\n",
       "      <td>-1.180673</td>\n",
       "      <td>-0.858800</td>\n",
       "      <td>-0.770402</td>\n",
       "      <td>-0.728512</td>\n",
       "      <td>-1.167846</td>\n",
       "      <td>-0.606429</td>\n",
       "      <td>-0.505667</td>\n",
       "      <td>-1.138973</td>\n",
       "      <td>-0.455587</td>\n",
       "      <td>-0.740604</td>\n",
       "      <td>-1.099731</td>\n",
       "      <td>-0.702302</td>\n",
       "      <td>-1.117713</td>\n",
       "      <td>-0.682462</td>\n",
       "      <td>-0.614434</td>\n",
       "      <td>-1.409214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.002234</td>\n",
       "      <td>0.058130</td>\n",
       "      <td>-0.303127</td>\n",
       "      <td>-0.080908</td>\n",
       "      <td>-0.058365</td>\n",
       "      <td>0.333884</td>\n",
       "      <td>-0.432852</td>\n",
       "      <td>0.130319</td>\n",
       "      <td>0.223477</td>\n",
       "      <td>-0.394973</td>\n",
       "      <td>-0.254728</td>\n",
       "      <td>0.125424</td>\n",
       "      <td>-0.537437</td>\n",
       "      <td>-0.327279</td>\n",
       "      <td>-0.112969</td>\n",
       "      <td>0.307482</td>\n",
       "      <td>-0.149643</td>\n",
       "      <td>-0.504885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.594128</td>\n",
       "      <td>0.774213</td>\n",
       "      <td>0.388495</td>\n",
       "      <td>0.517475</td>\n",
       "      <td>0.490519</td>\n",
       "      <td>0.954707</td>\n",
       "      <td>0.253546</td>\n",
       "      <td>0.681395</td>\n",
       "      <td>0.789308</td>\n",
       "      <td>0.943443</td>\n",
       "      <td>0.390901</td>\n",
       "      <td>0.745857</td>\n",
       "      <td>-0.077452</td>\n",
       "      <td>0.237476</td>\n",
       "      <td>0.967356</td>\n",
       "      <td>1.035598</td>\n",
       "      <td>0.193488</td>\n",
       "      <td>0.483112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.263059</td>\n",
       "      <td>2.208262</td>\n",
       "      <td>2.074796</td>\n",
       "      <td>3.445954</td>\n",
       "      <td>2.445008</td>\n",
       "      <td>2.537600</td>\n",
       "      <td>1.611094</td>\n",
       "      <td>2.182502</td>\n",
       "      <td>2.123748</td>\n",
       "      <td>3.125819</td>\n",
       "      <td>1.533450</td>\n",
       "      <td>2.180483</td>\n",
       "      <td>2.256892</td>\n",
       "      <td>3.243378</td>\n",
       "      <td>1.579670</td>\n",
       "      <td>2.089478</td>\n",
       "      <td>3.315606</td>\n",
       "      <td>1.897232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5   \\\n",
       "count  35.000000  35.000000  35.000000  35.000000  35.000000  35.000000   \n",
       "mean   -0.068168  -0.047086  -0.271721  -0.010764  -0.117387   0.143858   \n",
       "std     0.852268   1.101955   1.052590   1.152810   0.912579   1.153690   \n",
       "min    -1.923010  -1.801510  -1.908166  -1.886591  -2.010072  -2.186242   \n",
       "25%    -0.631240  -1.048411  -1.180673  -0.858800  -0.770402  -0.728512   \n",
       "50%    -0.002234   0.058130  -0.303127  -0.080908  -0.058365   0.333884   \n",
       "75%     0.594128   0.774213   0.388495   0.517475   0.490519   0.954707   \n",
       "max     1.263059   2.208262   2.074796   3.445954   2.445008   2.537600   \n",
       "\n",
       "              6          7          8          9          10         11  \\\n",
       "count  35.000000  35.000000  35.000000  35.000000  35.000000  35.000000   \n",
       "mean   -0.405909  -0.074556   0.133895   0.089220  -0.071600   0.041266   \n",
       "std     1.001973   1.209683   1.113467   1.436906   0.632524   1.053231   \n",
       "min    -2.530499  -3.849462  -2.732487  -1.872328  -1.451265  -1.809318   \n",
       "25%    -1.167846  -0.606429  -0.505667  -1.138973  -0.455587  -0.740604   \n",
       "50%    -0.432852   0.130319   0.223477  -0.394973  -0.254728   0.125424   \n",
       "75%     0.253546   0.681395   0.789308   0.943443   0.390901   0.745857   \n",
       "max     1.611094   2.182502   2.123748   3.125819   1.533450   2.180483   \n",
       "\n",
       "              12         13         14         15         16         17  \n",
       "count  35.000000  35.000000  35.000000  35.000000  35.000000  35.000000  \n",
       "mean   -0.619987  -0.169259  -0.153238   0.145333   0.050195  -0.455814  \n",
       "std     0.943288   0.986321   1.215183   1.091717   1.029160   1.118408  \n",
       "min    -3.247888  -1.670656  -3.281368  -2.039341  -1.511725  -2.338709  \n",
       "25%    -1.099731  -0.702302  -1.117713  -0.682462  -0.614434  -1.409214  \n",
       "50%    -0.537437  -0.327279  -0.112969   0.307482  -0.149643  -0.504885  \n",
       "75%    -0.077452   0.237476   0.967356   1.035598   0.193488   0.483112  \n",
       "max     2.256892   3.243378   1.579670   2.089478   3.315606   1.897232  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left-out data set\n",
    "pd.DataFrame(X_lo).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005198ec-bcdb-427d-b42a-2521aa2e69dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "Initialization converged: True\n",
      "VGMM clustering:\n",
      " [[46  1]\n",
      " [45  0]] \n",
      "\n",
      "Initialization 0\n",
      "Initialization converged: True\n",
      "VGMM left-out clustering:\n",
      " [[21  0]\n",
      " [14  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "n_components = 2\n",
    "random_state = 48\n",
    "\n",
    "labels = BayesianGaussianMixture(n_components=n_components, random_state=random_state, verbose=1).fit_predict(X)\n",
    "print(\"VGMM clustering:\\n\", confusion_matrix(X_indicator, labels), '\\n')\n",
    "\n",
    "lo_labels = BayesianGaussianMixture(n_components=n_components, random_state=random_state, verbose=1).fit(X).predict(X_lo)\n",
    "print(\"VGMM left-out clustering:\\n\", confusion_matrix(X_lo_indicator, lo_labels))\n",
    "\n",
    "#BayesianGaussianMixture(n_components=n_components, random_state=random_state).fit(X).covariances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0a744-1c81-4c72-a003-df964b735e66",
   "metadata": {},
   "source": [
    "### Create VaMSL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f389cfb-1e3e-4adf-a330-f0646587432c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vamsl.models.graph import ErdosReniDAGDistribution, ScaleFreeDAGDistribution, UniformDAGDistributionRejection\n",
    "from vamsl.models import MixtureLinearGaussian, MixtureDenseNonlinearGaussian\n",
    "from vamsl.models import LinearGaussian, DenseNonlinearGaussian\n",
    "from vamsl.target import make_graph_model\n",
    "\n",
    "# BN settings\n",
    "n_vars = X.shape[1] # number of variables in each component BN\n",
    "struct_eq_type = 'linear' # BN function class: 'linear' or 'nonlinear'\n",
    "graph_type = 'er' # Random graph structure: 'sf' (scale-free) or 'er' (Erdos-Renyi)\n",
    "\n",
    "# Derived variables\n",
    "n_components = 1\n",
    "linear = True if struct_eq_type == 'linear' else False\n",
    "\n",
    "# Model specification \n",
    "if linear:\n",
    "    graph_model = make_graph_model(n_vars=n_vars, graph_prior_str=graph_type, edges_per_node=2)\n",
    "    lik = MixtureLinearGaussian(n_vars=n_vars, obs_noise=0.1)  \n",
    "    component_lik = LinearGaussian(n_vars=n_vars, obs_noise=0.1)\n",
    "else:\n",
    "    graph_model = make_graph_model(n_vars=n_vars, graph_prior_str=graph_type, edges_per_node=2)\n",
    "    lik = MixtureDenseNonlinearGaussian(n_vars=n_vars, obs_noise=0.1)  \n",
    "    component_lik = DenseNonlinearGaussian(n_vars=n_vars, obs_noise=0.1, hidden_layers=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f8bc36f-f45a-4498-95de-c9efec994225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior shapes:\n",
      "q_z:     (1, 10, 18, 18, 2)\n",
      "q_theta: (1, 10, 18, 18)\n",
      "log_q_c: (92, 1)\n",
      "q_pi:    (1,)\n"
     ]
    }
   ],
   "source": [
    "from vamsl.inference import VaMSL\n",
    "\n",
    "# Create VaMSL and initialize posteriors\n",
    "vamsl = VaMSL(x=X, graph_model=graph_model, mixture_likelihood_model=lik, component_likelihood_model=component_lik, n_mixture_grad_mc_samples=1)\n",
    "key, subk = random.split(key)\n",
    "vamsl.initialize_posteriors(key=subk, n_components=n_components, n_particles=10, linear=linear)#, init_q_c=jnp.exp(vamsl.get_posteriors()[2]))\n",
    "#vamsl.set_E(jnp.array([adjacency]))\n",
    "\n",
    "print('Posterior shapes:')\n",
    "posts = vamsl.get_posteriors()\n",
    "print('q_z:     ' + str(posts[0].shape)) # [n_components, n_particls, d, l, 2]\n",
    "print('q_theta: ' + str(posts[1].shape)) if linear else print('q_theta: ' + str(len(posts[1]))) # leading dim of n_components\n",
    "print('log_q_c: ' + str(posts[2].shape)) # [n_observations, n_components]\n",
    "print('q_pi:    ' + str(posts[3].shape)) # [n_components,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b8a1a-6539-4918-909b-9fe0b7f9336d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1750x500 with 14 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component   1 | iteration 1000 | alpha   50.0 | beta 1000.0 | #cyclic   0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# CAVI and SVGD vars\n",
    "n_cavi_updates, steps = 0, 200\n",
    "\n",
    "# CAVI-loop\n",
    "for cavi_update in range(n_cavi_updates):\n",
    "    key, subk = random.split(key)\n",
    "    # Optimize q(Z, \\Theta)\n",
    "    vamsl.update_particle_posteriors(key=subk, steps=steps, callback_every=steps,\n",
    "                                     callback=vamsl.visualize_callback(), linear=linear)\n",
    "\n",
    "    # Update to optimal q(c) and q(\\pi)\n",
    "    vamsl.update_responsibilities_and_weights()\n",
    "    print(f'CAVI update number {cavi_update+1}/{n_cavi_updates}')\n",
    "    \n",
    "    # Print current clustering\n",
    "    order = vamsl.identify_MAP_classification_ordering(ground_truth_indicator=indicator[observed])\n",
    "    y_pred = [order[k] for k in [jnp.argmax(c_i) for c_i in vamsl.get_posteriors()[2]]]\n",
    "    print('MAP clustering: \\n', confusion_matrix(indicator[observed], y_pred))\n",
    "    \n",
    "# Final CAVI update with more SVGD steps to ensure annealing unto acyclic graphs\n",
    "key, subk = random.split(key)\n",
    "vamsl.update_particle_posteriors(key=subk, steps=3000, callback_every=200, callback=vamsl.visualize_callback(), linear=linear)\n",
    "vamsl.update_responsibilities_and_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b3965d-afcc-418c-a2bc-30cc7eb13bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums of responsibilities:\n",
      "[51.866024 40.133976]\n",
      "Sum of entropy of responsibilities:\n",
      "-2.3791049\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Component 1       0.57      0.49      0.53        47\n",
      " Component 2       0.54      0.62      0.58        45\n",
      "\n",
      "    accuracy                           0.55        92\n",
      "   macro avg       0.56      0.56      0.55        92\n",
      "weighted avg       0.56      0.55      0.55        92\n",
      "\n",
      "Order:  [1 0]\n",
      "[[23 24]\n",
      " [17 28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_indicator = indicator[observed]\n",
    "\n",
    "print('Sums of responsibilities:')\n",
    "print(jnp.sum(jnp.exp(vamsl.get_posteriors()[2]), axis=0))\n",
    "print('Sum of entropy of responsibilities:')\n",
    "print(jnp.sum(jnp.exp(vamsl.get_posteriors()[2])*vamsl.get_posteriors()[2]))\n",
    "y_true, order = X_indicator, vamsl.identify_MAP_classification_ordering(ground_truth_indicator=X_indicator)\n",
    "y_pred = [order[k] for k in [jnp.argmax(c_i) for c_i in vamsl.get_posteriors()[2]]]\n",
    "if n_components==2:\n",
    "    print('Classification report:')\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, target_names=['Component 1', 'Component 2']))\n",
    "print('Order: ', order)\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2694acdc-771a-4ad2-992e-aa700ee14d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.5624045 , 0.43759552], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BCD Nets\n",
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c6ac1e0-d782-4b43-8fcd-eee0f0b6e465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 158.51\n"
     ]
    }
   ],
   "source": [
    "# BCD Nets\n",
    "\n",
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ddff377-a9fc-43f1-adcd-2d9114127bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "held-out responsibilities: [155.65939331 163.74350542]\n",
      "neg. LL 145.94\n"
     ]
    }
   ],
   "source": [
    "# BCD Nets\n",
    "\n",
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d359d-3752-4378-aca2-e8d1a402e529",
   "metadata": {},
   "source": [
    "### Ground truth\n",
    "0. linear (all data)\n",
    "1. linear (500 datapoints)\n",
    "2. non-linear (500 datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7307884-fa07-4157-a129-e8ca4307961d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02943c51-5eb0-4226-8b9c-d22d68111ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Component    1 |  E-SHD: 17.7    AUROC:  0.57\n"
     ]
    }
   ],
   "source": [
    "from vamsl.metrics import expected_shd, threshold_metrics, neg_ave_log_likelihood\n",
    "\n",
    "# Get component datasets\n",
    "#datas = [X[(X_indicator==k).flatten(),:] for k in range(n_components)]\n",
    "\n",
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    eshd = expected_shd(dist=dist, g=adjacency)       \n",
    "    auroc = threshold_metrics(dist=dist, g=adjacency)['roc_auc']\n",
    "    #negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=data.x_ho)\n",
    "    \n",
    "    print(f' Component {k+1:4d} |  E-SHD: {eshd:4.1f}    AUROC: {auroc:5.2f}')#    neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d2f7fb3-0b4e-4e5e-a6c8-bdf09e478fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 352.51\n"
     ]
    }
   ],
   "source": [
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a253e9-1b6c-479a-bdd2-5756992be62a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 351.96\n"
     ]
    }
   ],
   "source": [
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6413ecfc-f3ed-4d24-bd59-87c469d7afba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL  359.85845637583895\n"
     ]
    }
   ],
   "source": [
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fea14-2249-4097-95a4-8244b7e0eeb6",
   "metadata": {},
   "source": [
    "### One component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e65dd99-eff5-48ec-aa4c-93dddede6c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 47.64\n"
     ]
    }
   ],
   "source": [
    "# BCD Nets data\n",
    "\n",
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef32158-2856-4501-b165-72af9ecd1a63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 42.38\n"
     ]
    }
   ],
   "source": [
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7592924-49cd-45be-85b5-d58b4c53b612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 43.57\n"
     ]
    }
   ],
   "source": [
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate predictive density of left-out data\n",
    "    negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo)/X_lo.shape[0]\n",
    "    \n",
    "    print(f'neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f12a9-f1f6-41e0-83d8-632808239d12",
   "metadata": {},
   "source": [
    "### Two components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6680ac-8137-45e8-8b5c-559c5cc3043d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.5950506 , 0.40494943], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BCD Nets\n",
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea75349-de46-42f1-a981-5388aba2b6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 60.48\n"
     ]
    }
   ],
   "source": [
    "# BCD Nets\n",
    "\n",
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c6090a-b2b1-4423-9a40-367c562a7aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "held-out responsibilities: [58.04676884 65.7165726 ]\n",
      "neg. LL 53.45\n"
     ]
    }
   ],
   "source": [
    "# BCD Nets\n",
    "\n",
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd656a89-a910-449d-8f81-2ba7d0c683ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.25614512, 0.7438549 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "192a686d-1d94-4d00-b6c2-b9388bf1620f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 73.34\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d487f21-f099-4c16-8b70-aa46ecc9e06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "held-out responsibilities: [72.10863315 74.53500079]\n",
      "neg. LL 57.30\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb6bf3e6-dfa6-406c-963b-df979744aa0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.09735344, 0.9026466 ], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efa865ab-b0bd-4b17-acc9-6a46404b6c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 53.15\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1689ccc-5ed5-4f56-badb-83ab14ab168b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 50.17\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c275135-34ac-4241-9918-b773214b1545",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Three components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "026c2338-db4f-443b-b197-3ef0b0e23f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.2916099 , 0.40393355, 0.30445644], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3d17ad5-69d8-49d8-9e01-82a0499483fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 64.07\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f53bf27c-2bf5-4260-9242-85d2ecbc384c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 53.65\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92731c-e349-49d8-b427-86223e1f4934",
   "metadata": {},
   "source": [
    "### Four components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dfdc6a5-a7e3-4536-99a9-ed5d9e1eadd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.07333528, 0.08092984, 0.550729  , 0.29500586], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8835c34a-cc73-4172-a312-199296868888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 59.32\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d66894a7-3a58-4aed-abea-8c7b7a632bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "held-out responsibilities: [77.87623398 74.46787088 54.27890074 63.65507151]\n",
      "neg. LL 49.05\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):   \n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c7cbab2-e9de-44f9-be06-24dc66f55233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.19552918e+240, 2.42086350e+254, 4.97122976e+268, 3.80680964e+234])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(rs - rs.sum(axis=1)[..., None]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b473fc-b852-4995-997b-935d5e10bcfe",
   "metadata": {},
   "source": [
    "### Two components, data from two general perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92fe58ad-bc2f-44f5-9751-89d3511077b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.8221602 , 0.17783985], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95805fac-66d1-4139-b30d-06b87b97fe04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg. LL 20.07\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for posterior assignment probabilities\n",
    "mixing_probs = vamsl.get_posteriors()[3]/vamsl.get_posteriors()[3].sum()\n",
    "negll = 0\n",
    "for i in range(X_lo.shape[0]):\n",
    "    temp_negll = 0\n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        temp_negll += mixing_probs[k] * neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "    negll += temp_negll\n",
    "    \n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d05ff467-ae69-4e90-b8aa-4b9921380cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "held-out responsibilities: [20.22387931 21.97718892 -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.        ]\n",
      "neg. LL 20.24\n"
     ]
    }
   ],
   "source": [
    "# Calculate neg log liks for MAP assignments \n",
    "negll = 0\n",
    "rs = np.zeros((X_lo.shape[0], n_components))\n",
    "for i in range(X_lo.shape[0]):   \n",
    "    for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "        # Get particle distribution for component\n",
    "        q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "        dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "\n",
    "        # Calculate predictive density of left-out data\n",
    "        rs[i,k] = vamsl.compute_log_responsibility(X_lo[i,:].reshape((1,-1)), dist, vamsl.get_posteriors()[3][k])\n",
    "        \n",
    "    q_g_k = vamsl.particle_to_g_lim(vamsl.get_posteriors()[0][np.argmax(rs[i])], vamsl.get_E()[np.argmax(rs[i])])\n",
    "    dist = vamsl.get_empirical(q_g_k, vamsl.get_posteriors()[1][np.argmax(rs[i])])\n",
    "    negll += neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=X_lo[i,:].reshape((1,-1)))\n",
    "    \n",
    "print('held-out responsibilities:', -rs.sum(axis=0)/X_lo.shape[0])\n",
    "print(f'neg. LL {negll/X_lo.shape[0]:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b1e35575-1d3f-4512-971a-a1f1cd5e3acf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Component    1 |  E-SHD: 17.9    AUROC:  0.58\n",
      " Component    2 |  E-SHD: 17.9    AUROC:  0.59\n"
     ]
    }
   ],
   "source": [
    "from vamsl.metrics import expected_shd, threshold_metrics, neg_ave_log_likelihood\n",
    "\n",
    "# Get component datasets\n",
    "#datas = [X[(X_indicator==k).flatten(),:] for k in range(n_components)]\n",
    "\n",
    "# Loop over components and calculate metrics\n",
    "for k, q_z_k, q_theta_k in zip(range(n_components), vamsl.get_posteriors()[0], vamsl.get_posteriors()[1]):\n",
    "    # Get particle distribution for component\n",
    "    q_g_k = vamsl.particle_to_g_lim(q_z_k, vamsl.get_E()[k])\n",
    "    dist = vamsl.get_empirical(q_g_k, q_theta_k)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    eshd = expected_shd(dist=dist, g=adjacency)       \n",
    "    auroc = threshold_metrics(dist=dist, g=adjacency)['roc_auc']\n",
    "    #negll = neg_ave_log_likelihood(dist=dist, eltwise_log_likelihood=vamsl.eltwise_component_log_likelihood_observ, x=data.x_ho)\n",
    "    \n",
    "    print(f' Component {k+1:4d} |  E-SHD: {eshd:4.1f}    AUROC: {auroc:5.2f}')#    neg. LL {negll:5.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "48f8efb3-4bf9-483f-a9d1-b5b47e1c8c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sums of responsibilities:\n",
      "[167.54282   35.457172]\n",
      "Sum of entropy of responsibilities:\n",
      "-87.70003\n",
      "[[111   1]\n",
      " [ 90   1]]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_indicator = indicator[observed]\n",
    "\n",
    "print('Sums of responsibilities:')\n",
    "print(jnp.sum(jnp.exp(vamsl.get_posteriors()[2]), axis=0))\n",
    "print('Sum of entropy of responsibilities:')\n",
    "print(jnp.sum(jnp.exp(vamsl.get_posteriors()[2])*vamsl.get_posteriors()[2]))\n",
    "y_true, order = X_indicator, vamsl.identify_MAP_classification_ordering(ground_truth_indicator=X_indicator)\n",
    "y_pred = [order[k] for k in [jnp.argmax(c_i) for c_i in vamsl.get_posteriors()[2]]]\n",
    "if n_components==2:\n",
    "    print('Classification report:')\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, target_names=['Component 1', 'Component 2']))\n",
    "print('Order: ', order)\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
